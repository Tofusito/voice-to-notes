
# Whisper to Markdown Processing Pipeline

## Overview

This project automates the process of converting audio files into well-structured Markdown notes. The pipeline uses Docker, Whisper.cpp, and a custom Python script to transcribe audio files, format the transcription according to a Markdown template, and then enhance the transcription by sending it to a language model API for further processing.

## Tools and Technologies Used

- **Ollama**: A lightweight tool that supports various LLM models, including Whisper.
- **Docker**: Used to run Whisper.cpp in a containerized environment, ensuring consistency across different systems.
- **Whisper.cpp**: An efficient C++ implementation of OpenAI's Whisper model, used to transcribe audio files.
- **Python**: The primary language for scripting the automation process, including handling Docker, sending requests to the language model API, and processing files.
- **Requests** (Python library): Used to send HTTP POST requests to the language model API.
- **Markdown**: The output format for the transcriptions, structured according to a predefined template.
- **AI Models**:
    - **Whisper.cpp**: Handles the transcription of audio files into text. It is a reduced version written in C++ of the original Whisper by OpenAI.
    - **LLaMA (Large Language Model Meta AI)**: Specifically, the `llama3.1:latest` model is used to process the transcribed text, enhancing and structuring it according to the provided Markdown template.

## New Features

- **Automatic Title Generation**: The script now requests a simple, descriptive title from the LLaMA API to name the generated Markdown files, ensuring that file names are descriptive and relevant.
- **Automatic Temporary File Deletion**: The transcribed text files (.txt) generated by Whisper.cpp are automatically deleted once the corresponding Markdown file has been created, helping to keep the output directory clean.
- **Directory Verification**: If the directories specified in the configuration do not exist, the script prompts the user to create them or provide valid new paths, ensuring proper setup before execution.

## Requirements

- **Ollama**: Ensure `Llama3.1:latest` is installed.
- **Docker**: Ensure Docker is installed and running on your machine.
- **Python 3.x**: Required to run the script.
- **Python Libraries**:
  - `requests`
- **Whisper.cpp Docker Image**: Ensure the `whisper-cpp-alpine` Docker image is available locally.

## Setup

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-repo/whisper-to-markdown.git
   cd whisper-to-markdown
   ```

2. **Install Python Dependencies**:
   Make sure to have `requests` installed:
   ```bash
   pip install requests
   ```

3. **Configure the Pipeline**:
   - Configure the input, output, and Markdown output directories in `config.json`.
   - Place your audio files in the specified input directory.

## Usage

1. **Place Audio Files**:
   - Place all audio files you want to transcribe in the directory specified as `input_dir` in `config.json`. Supported formats include `.wav`, `.mp3`, `.m4a`, `.ogg`, and `.flac`.

2. **Run the Script**:
   - Execute the Python script to start the process. The script will first run the Docker container to transcribe the audio files, then process the transcriptions with the LLaMA API, and finally save the structured Markdown output in the `output_md_dir`.

3. **Output**:
   - The final Markdown files will be available in the `output_md_dir`, named according to the automatically generated title.

## Example

**Input:**

- `inputs/meeting_audio.mp3`

**Output:**

- `outputs_md/Title_of_the_meeting.md`

## Project Structure

```bash
.
├── config/           # Application configuration
│   └── config.json   # Configuration file with paths and parameters
├── inputs/           # Directory for input audio files
├── outputs/          # Directory where Whisper.cpp saves transcriptions
├── outputs_md/       # Directory where the final Markdown files are saved
├── templates/        # Directory containing the Markdown template
│   └── template.md   # Markdown template used for structuring the output
├── main.py           # Main Python script that orchestrates the process
└── README.md         # Project documentation
```

## Additional Information

- **Error Handling**:
  - The script includes error handling for Docker execution and API requests. If an error occurs during any part of the process, it will be logged, and the script will attempt to continue processing remaining files.

- **Performance**:
  - The pipeline is designed for batch processing. Depending on the number of audio files and their duration, the processing time may vary. The total execution time is displayed at the end of the process.

## Conclusion

This project provides an automated and efficient solution for converting audio transcriptions into structured Markdown documents, leveraging the power of Docker and advanced language models. It is a versatile tool that can be adapted for various use cases, such as meeting notes, podcast transcriptions, or lecture summaries.
